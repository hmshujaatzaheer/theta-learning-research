# Î¸-Learning: Timing-Safe Neural Memory

[![Tests](https://github.com/hmshujaatzaheer/theta-learning-research/actions/workflows/tests.yml/badge.svg)](https://github.com/hmshujaatzaheer/theta-learning-research/actions/workflows/tests.yml)
[![codecov](https://codecov.io/gh/hmshujaatzaheer/theta-learning-research/branch/main/graph/badge.svg)](https://codecov.io/gh/hmshujaatzaheer/theta-learning-research)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[![Status: Research Proposal](https://img.shields.io/badge/Status-Research%20Proposal-yellow)]()
[![Theory: Proven](https://img.shields.io/badge/Theory-Proven-green)]()
[![Experiments: Pending](https://img.shields.io/badge/Experiments-Pending-orange)]()

## Overview

This repository contains the reference implementation and experimental infrastructure for the **Î¸-Learning Principle**, a mathematical framework for timing-safe neural memory as described in the PhD research proposal.

> **Important Disclaimer**: This repository distinguishes between:
> - âœ… **Implemented & Verified**: Core algorithms, theoretical complexity analysis
> - ğŸ”¬ **Requires Lab Validation**: Hardware timing measurements, benchmark scores, security evaluation
> - ğŸ“ **Mathematically Proven**: Theorems (proofs in proposal, code provides illustrations)

---

## Table of Contents

1. [What This Repository Contains](#what-this-repository-contains)
2. [What Requires Future Validation](#what-requires-future-validation)
3. [Installation](#installation)
4. [Repository Structure](#repository-structure)
5. [Mapping to Proposal](#mapping-to-proposal)
6. [Running the Code](#running-the-code)
7. [Research Phases](#research-phases)
8. [Citation](#citation)

---

## What This Repository Contains

### âœ… Implemented Now (This Repository)

| Component | File | Status | Description |
|-----------|------|--------|-------------|
| Î¸MN Core Algorithm | `src/core/theta_mn.py` | âœ… Complete | Basic Î¸-Memory Network implementation |
| Î¸MN(r) Low-Rank | `src/core/theta_mn_lr.py` | âœ… Complete | Low-rank factorized variant |
| EWC Integration | `src/core/ewc.py` | âœ… Complete | Elastic Weight Consolidation |
| FLOP Counter | `src/utils/complexity.py` | âœ… Complete | Operation counting for complexity verification |
| Theoretical Plots | `src/utils/theoretical_plots.py` | âœ… Complete | Complexity curves (theoretical, not empirical) |
| Timing Infrastructure | `src/utils/timing.py` | âœ… Complete | Measurement framework (NOT security validation) |
| Unit Tests | `tests/` | âœ… Complete | Correctness verification |

### ğŸ“ Mathematically Proven (Proofs in Proposal)

| Theorem | Proposal Section | Code Illustration | What Code Shows |
|---------|------------------|-------------------|-----------------|
| Theorem 1: Storage Leaks | Section 3 | `experiments/phase1_theory/theorem1_illustration.py` | Demonstrates variable timing in storage-based memory |
| Theorem 2: Î¸-Learning Timing-Safety | Section 4 | `experiments/phase1_theory/theorem2_illustration.py` | Shows constant FLOP count regardless of input |
| Theorem 3: Complexity Bounds | Section 4 | `experiments/phase1_theory/theorem3_verification.py` | Verifies O(dÂ²) and O(rd) operation counts |
| Theorem 4: Functional Equivalence | Section 5 | `experiments/phase1_theory/theorem4_illustration.py` | Demonstrates recall capability |
| Theorem 5: Universal Transformation | Section 7 | `experiments/phase1_theory/theorem5_illustration.py` | Shows transformation preserves functionality |

**Note**: Code *illustrates* theorems but does not *prove* them. Proofs are mathematical and in the proposal.

---

## What Requires Future Validation

### ğŸ”¬ Phase 2: Hardware Validation (Months 7-12)

| Experiment | File | Status | What's Needed |
|------------|------|--------|---------------|
| Constant-time on A100 | `experiments/phase2_implementation/gpu_timing_a100.py` | ğŸ”¬ Placeholder | Access to A100 GPU, statistical analysis |
| Constant-time on H100 | `experiments/phase2_implementation/gpu_timing_h100.py` | ğŸ”¬ Placeholder | Access to H100 GPU, statistical analysis |
| Memory bandwidth analysis | `experiments/phase2_implementation/memory_bandwidth.py` | ğŸ”¬ Placeholder | GPU profiling tools (NSight) |
| Wall-clock speedup | `experiments/phase2_implementation/wallclock_speedup.py` | ğŸ”¬ Placeholder | Optimized CUDA kernels |

**Required Resources**:
- NVIDIA A100/H100 GPUs
- CUDA profiling tools (NSight Compute, NSight Systems)
- Statistical analysis framework for timing measurements
- Minimum 1000 trials per configuration for statistical significance

### ğŸ”¬ Phase 3: Security Evaluation (Months 13-18)

| Experiment | File | Status | What's Needed |
|------------|------|--------|---------------|
| PROMPTPEEK reproduction | `experiments/phase3_security/promptpeek_baseline.py` | ğŸ”¬ Placeholder | Reproduce Wu et al. attack |
| Attack on Î¸MN | `experiments/phase3_security/attack_theta_mn.py` | ğŸ”¬ Placeholder | Attempt timing attacks on Î¸MN |
| Statistical timing analysis | `experiments/phase3_security/timing_statistics.py` | ğŸ”¬ Placeholder | Mutual information estimation |
| Covert channel capacity | `experiments/phase3_security/covert_channel.py` | ğŸ”¬ Placeholder | Information-theoretic analysis |

**Required Resources**:
- Isolated measurement environment (no other processes)
- High-precision timers (rdtsc or equivalent)
- Statistical tools for mutual information estimation
- Adversarial evaluation framework

### ğŸ”¬ Phase 4: Benchmark Evaluation (Months 19-24)

| Experiment | File | Status | What's Needed |
|------------|------|--------|---------------|
| MMLU evaluation | `experiments/phase4_benchmarks/mmlu_eval.py` | ğŸ”¬ Placeholder | Trained Î¸MN model, MMLU dataset |
| GSM8K evaluation | `experiments/phase4_benchmarks/gsm8k_eval.py` | ğŸ”¬ Placeholder | Trained Î¸MN model, GSM8K dataset |
| HumanEval evaluation | `experiments/phase4_benchmarks/humaneval_eval.py` | ğŸ”¬ Placeholder | Trained Î¸MN model, HumanEval dataset |
| Comparison with TTT-E2E | `experiments/phase4_benchmarks/ttt_comparison.py` | ğŸ”¬ Placeholder | TTT-E2E reproduction |
| Comparison with Mamba | `experiments/phase4_benchmarks/mamba_comparison.py` | ğŸ”¬ Placeholder | Mamba reproduction |

**Required Resources**:
- Large-scale training infrastructure (8+ GPUs for weeks)
- Pre-training data (CommonCrawl, The Pile, etc.)
- Benchmark datasets and evaluation harnesses
- Baseline model reproductions

---

## Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/theta-learning-research.git
cd theta-learning-research

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

---

## Repository Structure

```
theta-learning-research/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ VALIDATION_STATUS.md         # Detailed validation status
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package setup
â”œâ”€â”€ pyproject.toml              # Modern Python packaging
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ core/                   # Core implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ theta_mn.py         # âœ… Î¸MN implementation
â”‚   â”‚   â”œâ”€â”€ theta_mn_lr.py      # âœ… Î¸MN(r) low-rank variant
â”‚   â”‚   â”œâ”€â”€ ewc.py              # âœ… Elastic Weight Consolidation
â”‚   â”‚   â””â”€â”€ transformer.py      # âœ… Baseline Transformer attention
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Full model implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ theta_lm.py         # Language model with Î¸MN layers
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ complexity.py       # âœ… FLOP counting
â”‚   â”‚   â”œâ”€â”€ timing.py           # âœ… Timing measurement infrastructure
â”‚   â”‚   â””â”€â”€ theoretical_plots.py # âœ… Theoretical complexity plots
â”‚   â”‚
â”‚   â””â”€â”€ baselines/              # Baseline implementations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ kv_cache.py         # Standard KV-cache (for comparison)
â”‚       â””â”€â”€ linear_attention.py # Linear attention baseline
â”‚
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_theta_mn.py        # âœ… Core algorithm tests
â”‚   â”œâ”€â”€ test_theta_mn_lr.py     # âœ… Low-rank variant tests
â”‚   â”œâ”€â”€ test_complexity.py      # âœ… Complexity verification tests
â”‚   â””â”€â”€ test_functional.py      # âœ… Functional equivalence tests
â”‚
â”œâ”€â”€ experiments/                # Experimental protocols
â”‚   â”œâ”€â”€ phase1_theory/          # âœ… Theoretical illustrations
â”‚   â”‚   â”œâ”€â”€ theorem1_illustration.py
â”‚   â”‚   â”œâ”€â”€ theorem2_illustration.py
â”‚   â”‚   â”œâ”€â”€ theorem3_verification.py
â”‚   â”‚   â”œâ”€â”€ theorem4_illustration.py
â”‚   â”‚   â””â”€â”€ theorem5_illustration.py
â”‚   â”‚
â”‚   â”œâ”€â”€ phase2_implementation/  # ğŸ”¬ Hardware validation (placeholder)
â”‚   â”‚   â”œâ”€â”€ README.md           # Protocol documentation
â”‚   â”‚   â”œâ”€â”€ gpu_timing_a100.py
â”‚   â”‚   â”œâ”€â”€ gpu_timing_h100.py
â”‚   â”‚   â””â”€â”€ wallclock_speedup.py
â”‚   â”‚
â”‚   â”œâ”€â”€ phase3_security/        # ğŸ”¬ Security evaluation (placeholder)
â”‚   â”‚   â”œâ”€â”€ README.md           # Protocol documentation
â”‚   â”‚   â”œâ”€â”€ promptpeek_baseline.py
â”‚   â”‚   â”œâ”€â”€ attack_theta_mn.py
â”‚   â”‚   â””â”€â”€ timing_statistics.py
â”‚   â”‚
â”‚   â””â”€â”€ phase4_benchmarks/      # ğŸ”¬ Benchmark evaluation (placeholder)
â”‚       â”œâ”€â”€ README.md           # Protocol documentation
â”‚       â”œâ”€â”€ mmlu_eval.py
â”‚       â”œâ”€â”€ gsm8k_eval.py
â”‚       â””â”€â”€ humaneval_eval.py
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ THEOREMS.md             # Theorem statements and proof sketches
â”‚   â”œâ”€â”€ ALGORITHMS.md           # Algorithm descriptions
â”‚   â””â”€â”€ EXPERIMENTAL_PROTOCOLS.md # Detailed experimental protocols
â”‚
â”œâ”€â”€ figures/                    # Generated figures
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ data/                       # Data directory
â”‚   â”œâ”€â”€ raw/                    # Raw experimental data
â”‚   â””â”€â”€ processed/              # Processed results
â”‚
â””â”€â”€ scripts/                    # Utility scripts
    â”œâ”€â”€ generate_theoretical_plots.py
    â””â”€â”€ run_all_tests.py
```

---

## Mapping to Proposal

### Direct Correspondence

| Proposal Section | Repository Location | Status |
|-----------------|---------------------|--------|
| Section 4: Î¸-Learning Principle | `src/core/theta_mn.py` | âœ… Implemented |
| Section 4: Theorem 2 (Timing-Safety) | `experiments/phase1_theory/theorem2_illustration.py` | âœ… Illustrated |
| Section 4: Theorem 3 (Complexity) | `src/utils/complexity.py` | âœ… Verified |
| Section 5: Functional Recall | `tests/test_functional.py` | âœ… Tested |
| Section 6: Î¸MN(r) Low-Rank | `src/core/theta_mn_lr.py` | âœ… Implemented |
| Section 6: EWC | `src/core/ewc.py` | âœ… Implemented |
| Section 9: Phase 1 | `experiments/phase1_theory/` | âœ… Complete |
| Section 9: Phase 2 | `experiments/phase2_implementation/` | ğŸ”¬ Placeholder |
| Section 9: Phase 3 | `experiments/phase3_security/` | ğŸ”¬ Placeholder |
| Section 9: Phase 4 | `experiments/phase4_benchmarks/` | ğŸ”¬ Placeholder |

### Figure Correspondence

| Proposal Figure | Repository File | Type |
|----------------|-----------------|------|
| Figure 3: Complexity Comparison | `figures/complexity_comparison.pdf` | ğŸ“ Theoretical |
| Figure 4: Î¸MN(r) Architecture | `docs/architecture.md` | ğŸ“ Diagram |
| Figure 5: Speedup | `figures/speedup_theoretical.pdf` | ğŸ“ Theoretical |

---

## Running the Code

### Quick Start

```bash
# Run all tests
python -m pytest tests/ -v

# Generate theoretical plots
python scripts/generate_theoretical_plots.py

# Run theorem illustrations
python experiments/phase1_theory/theorem2_illustration.py
python experiments/phase1_theory/theorem3_verification.py
```

### Example: Basic Î¸MN Usage

```python
from src.core.theta_mn import ThetaMemoryNetwork

# Initialize Î¸MN
model = ThetaMemoryNetwork(d=512, lr=0.01)

# Process a sequence
for token in sequence:
    output = model.forward(token)
    model.update(token, target)

# Query the memory
answer = model.query(question)
```

### Example: Verify Complexity

```python
from src.utils.complexity import count_flops

# Count FLOPs for Î¸MN vs Transformer
theta_flops = count_flops('theta_mn', d=4096, r=512, n=1)  # Per token
transformer_flops = count_flops('transformer', d=4096, n=8192)  # Per token at n=8K

print(f"Î¸MN(512): {theta_flops} FLOPs per token")
print(f"Transformer at 8K: {transformer_flops} FLOPs per token")
print(f"Ratio: {transformer_flops / theta_flops:.1f}x")
```

---

## Research Phases

### Phase 1: Theoretical Foundations (âœ… This Repository)

**Timeline**: Months 1-6  
**Status**: âœ… Complete in this repository

**Deliverables**:
- [x] Core algorithm implementation
- [x] Complexity verification code
- [x] Theorem illustrations
- [x] Unit tests
- [x] Theoretical plots

**How to use**:
```bash
# Run all Phase 1 experiments
cd experiments/phase1_theory
python theorem1_illustration.py
python theorem2_illustration.py
python theorem3_verification.py
```

---

### Phase 2: Implementation & Hardware Validation (ğŸ”¬ Placeholder)

**Timeline**: Months 7-12  
**Status**: ğŸ”¬ Protocols defined, requires lab execution

**What's Provided**:
- Experimental protocols in `experiments/phase2_implementation/README.md`
- Placeholder scripts with TODO markers
- Expected output formats

**What's Needed**:
1. **Hardware**: NVIDIA A100 or H100 GPUs
2. **Tools**: CUDA Toolkit, NSight Compute, NSight Systems
3. **Environment**: Isolated machine (no background processes)
4. **Time**: ~2-4 weeks of dedicated GPU time

**Key Experiments**:

| Experiment | Purpose | Success Criteria |
|------------|---------|------------------|
| `gpu_timing_a100.py` | Verify constant-time on A100 | CV < 1% across inputs |
| `gpu_timing_h100.py` | Verify constant-time on H100 | CV < 1% across inputs |
| `wallclock_speedup.py` | Measure actual speedup | Document real vs theoretical |

**Protocol** (from `experiments/phase2_implementation/README.md`):
```
1. Disable GPU boost clocks (fixed frequency)
2. Warm up GPU with 100 iterations
3. For each input configuration:
   a. Run 1000 trials
   b. Record high-precision timing
   c. Compute mean, std, CV
4. Statistical tests:
   a. ANOVA across input types
   b. Mutual information estimation
5. Report with confidence intervals
```

---

### Phase 3: Security Evaluation (ğŸ”¬ Placeholder)

**Timeline**: Months 13-18  
**Status**: ğŸ”¬ Protocols defined, requires lab execution

**What's Provided**:
- Attack reproduction protocols
- Statistical analysis framework
- Expected result formats

**What's Needed**:
1. Reproduce PROMPTPEEK attack (Wu et al.)
2. Attempt attack on Î¸MN
3. Measure mutual information between timing and input
4. Estimate covert channel capacity

**Key Experiments**:

| Experiment | Purpose | Success Criteria |
|------------|---------|------------------|
| `promptpeek_baseline.py` | Reproduce known attack | Match 95%+ accuracy from paper |
| `attack_theta_mn.py` | Attack Î¸MN | Document any information leakage |
| `timing_statistics.py` | Estimate MI(T; X) | MI < Îµ (define threshold) |

---

### Phase 4: Benchmark Evaluation (ğŸ”¬ Placeholder)

**Timeline**: Months 19-24  
**Status**: ğŸ”¬ Protocols defined, requires large-scale training

**What's Provided**:
- Evaluation harness structure
- Metric computation code
- Comparison framework

**What's Needed**:
1. **Training Infrastructure**: 8+ GPUs for 2-4 weeks
2. **Training Data**: Large corpus (100B+ tokens)
3. **Evaluation Datasets**: MMLU, GSM8K, HumanEval
4. **Baseline Models**: Trained Transformer, Mamba reproduction

**Key Experiments**:

| Experiment | Purpose | Success Criteria |
|------------|---------|------------------|
| `mmlu_eval.py` | Measure MMLU accuracy | Report with confidence intervals |
| `gsm8k_eval.py` | Measure math reasoning | Compare to Transformer baseline |
| `ttt_comparison.py` | Compare to TTT-E2E | Fair comparison (same params) |

---

## Validation Status Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VALIDATION STATUS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… COMPLETE (This Repository)                                  â”‚
â”‚  â”œâ”€â”€ Core Î¸MN implementation                                    â”‚
â”‚  â”œâ”€â”€ Î¸MN(r) low-rank variant                                    â”‚
â”‚  â”œâ”€â”€ EWC integration                                            â”‚
â”‚  â”œâ”€â”€ FLOP counting & complexity verification                    â”‚
â”‚  â”œâ”€â”€ Theoretical complexity plots                               â”‚
â”‚  â”œâ”€â”€ Theorem illustrations                                      â”‚
â”‚  â””â”€â”€ Unit tests                                                 â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ MATHEMATICALLY PROVEN (Proofs in Proposal)                  â”‚
â”‚  â”œâ”€â”€ Theorem 1: Storage-based memory leaks timing               â”‚
â”‚  â”œâ”€â”€ Theorem 2: Î¸-Learning achieves MI(T;X) = 0                 â”‚
â”‚  â”œâ”€â”€ Theorem 3: Complexity is O(dÂ²) or O(rd)                    â”‚
â”‚  â”œâ”€â”€ Theorem 4: Functional equivalence                          â”‚
â”‚  â””â”€â”€ Theorem 5: Universal transformation                        â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”¬ REQUIRES LAB VALIDATION                                     â”‚
â”‚  â”œâ”€â”€ Phase 2: Constant-time on real GPUs                        â”‚
â”‚  â”œâ”€â”€ Phase 2: Wall-clock speedup measurement                    â”‚
â”‚  â”œâ”€â”€ Phase 3: Security evaluation (attack attempts)             â”‚
â”‚  â”œâ”€â”€ Phase 3: Mutual information measurement                    â”‚
â”‚  â”œâ”€â”€ Phase 4: MMLU benchmark scores                             â”‚
â”‚  â”œâ”€â”€ Phase 4: GSM8K benchmark scores                            â”‚
â”‚  â”œâ”€â”€ Phase 4: HumanEval benchmark scores                        â”‚
â”‚  â””â”€â”€ Phase 4: Comparison with baselines                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Theoretical Plots

The plots in `figures/` are **theoretical** based on mathematical complexity analysis:

- `complexity_comparison.pdf` - O(nd) vs O(dÂ²) vs O(rd) curves
- `speedup_theoretical.pdf` - Theoretical speedup ratio n/r

**These are NOT empirical measurements**. Empirical validation requires Phase 2 experiments.

To regenerate:
```bash
python scripts/generate_theoretical_plots.py
```

---

## Citation

If you use this code, please cite the proposal:

```bibtex
@misc{theta-learning-2026,
  title={The Î¸-Learning Principle: A Universal Mathematical Framework for Timing-Safe Neural Memory},
  author={[Author]},
  year={2026},
  note={PhD Research Proposal}
}
```

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Acknowledgments

This work builds upon:
- Wu et al. (NDSS 2025) - PROMPTPEEK attack
- Gu & Dao (COLM 2024) - Mamba architecture
- Sun et al. (2025) - TTT-E2E
- Yao, Hu & Klimovic (EuroSys 2025) - DeltaZip

---

## Contact

For questions about this research, please open an issue or contact [email].
